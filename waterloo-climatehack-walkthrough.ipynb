{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9aba3d",
   "metadata": {},
   "source": [
    "# Hello!\n",
    "This is a walkthrough to train the University of Waterloo's submission model at ClimateHack 2023.\n",
    "\n",
    "To find all our experiments and code, see our original [repo](https://github.com/trevor-yu-087/climatehack.ai-2024), but beware, it is not documented, or well organized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b4294",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Environment set up\n",
    "\n",
    "We use docker to package dependencies. If you are using VScode or a JetBrains IDE, the devcontainers extension should be able to use the .devcontainer directory to build the docker image and use it as a development environment.\n",
    "\n",
    "If you do not want to use docker, you can (hopefully) get set up by running:\n",
    "\n",
    "- `pip install -r local-requirements.txt`\n",
    "- `conda install cartopy`\n",
    "- `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121`\n",
    "\n",
    "A machine with a CUDA enabled GPU is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b545c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Download data\n",
    "Our model used pv, hrv and weather data.\n",
    "\n",
    "For this example we'll only be downloading a few months of data.\n",
    "\n",
    "Note that you have to download the [indices.json](https://github.com/climatehackai/getting-started-2023/blob/main/indices.json) file and place it in the same directory as the data that gets downloaded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0d73a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1194: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9520314b1add482aa7599a95a0f3a9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 33 files:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/workspaces/waterloo-climatehack/data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "from os import makedirs\n",
    "\n",
    "datadir = \"/workspaces/waterloo-climatehack/data\" # change this\n",
    "makedirs(datadir, exist_ok=True)\n",
    "\n",
    "huggingface_hub.snapshot_download(\n",
    "    repo_id=\"climatehackai/climatehackai-2023\", \n",
    "    local_dir=datadir, \n",
    "    cache_dir=datadir + '/cache',\n",
    "    local_dir_use_symlinks=False, \n",
    "    repo_type=\"dataset\",\n",
    "    ignore_patterns=[\"aerosols/*\", \"satellite-nonhrv/*\"],\n",
    "    allow_patterns=[\"*10.zarr.zip\", \"*11.zarr.zip\", \"*.parquet\", \"*metadata.csv\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614fa250",
   "metadata": {},
   "source": [
    "# Generating PV  Features\n",
    "We generate site specific features (such as the site's max and average output during each month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b384e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15636434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing january\n",
      "Processing february\n",
      "Processing march\n",
      "Processing april\n",
      "Processing may\n",
      "Processing june\n",
      "Processing july\n",
      "Processing august\n",
      "Processing september\n",
      "Processing october\n",
      "Processing november\n",
      "Processing december\n"
     ]
    }
   ],
   "source": [
    "years = [2020, 2021]\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "\n",
    "for i, month_name in enumerate(months):\n",
    "    print(f'Processing {month_name}')\n",
    "    month = pd.read_parquet([datadir + f'/pv/{year}/{i+1}.parquet' for year in [2020,2021]])\n",
    "    month = month.drop(['generation_wh'], axis=1).reorder_levels(['ss_id', 'timestamp'])\n",
    "\n",
    "    site_ids = month.index.get_level_values(0).unique().values\n",
    "\n",
    "    monthly_avg, monthly_max, monthly_average_max = [], [], []\n",
    "\n",
    "    for site in site_ids:\n",
    "        a = month.loc[site].between_time('5:00', '22:00')\n",
    "        monthly_max.append(a.power.max())\n",
    "        monthly_avg.append(a.power.mean())\n",
    "        monthly_average_max.append(a.groupby([a.index.hour, a.index.minute]).power.mean().max())\n",
    "\n",
    "    frame = pd.DataFrame(np.array([monthly_avg, monthly_max, monthly_average_max]).T, index=site_ids)\n",
    "    frame.columns = [f'{month_name}_avg', f'{month_name}_max', f'{month_name}_average_max']\n",
    "\n",
    "    if i == 0:\n",
    "        pv_metrics_frame = frame\n",
    "    else:\n",
    "        pv_metrics_frame = pv_metrics_frame.join(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "158ddfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>january_avg</th>\n",
       "      <th>january_max</th>\n",
       "      <th>january_average_max</th>\n",
       "      <th>february_avg</th>\n",
       "      <th>february_max</th>\n",
       "      <th>february_average_max</th>\n",
       "      <th>march_avg</th>\n",
       "      <th>march_max</th>\n",
       "      <th>march_average_max</th>\n",
       "      <th>april_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>september_average_max</th>\n",
       "      <th>october_avg</th>\n",
       "      <th>october_max</th>\n",
       "      <th>october_average_max</th>\n",
       "      <th>november_avg</th>\n",
       "      <th>november_max</th>\n",
       "      <th>november_average_max</th>\n",
       "      <th>december_avg</th>\n",
       "      <th>december_max</th>\n",
       "      <th>december_average_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0.034619</td>\n",
       "      <td>0.726833</td>\n",
       "      <td>0.169660</td>\n",
       "      <td>0.102621</td>\n",
       "      <td>0.919714</td>\n",
       "      <td>0.351934</td>\n",
       "      <td>0.114527</td>\n",
       "      <td>0.978294</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.255650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510344</td>\n",
       "      <td>0.092981</td>\n",
       "      <td>0.912645</td>\n",
       "      <td>0.290926</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.807710</td>\n",
       "      <td>0.344670</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.553282</td>\n",
       "      <td>0.143006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.347593</td>\n",
       "      <td>0.117526</td>\n",
       "      <td>0.063945</td>\n",
       "      <td>0.510123</td>\n",
       "      <td>0.207965</td>\n",
       "      <td>0.137374</td>\n",
       "      <td>0.813030</td>\n",
       "      <td>0.372940</td>\n",
       "      <td>0.238742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352374</td>\n",
       "      <td>0.071822</td>\n",
       "      <td>0.683270</td>\n",
       "      <td>0.230175</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>0.498327</td>\n",
       "      <td>0.141312</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.219477</td>\n",
       "      <td>0.090823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>0.018289</td>\n",
       "      <td>0.214462</td>\n",
       "      <td>0.072340</td>\n",
       "      <td>0.045558</td>\n",
       "      <td>0.415719</td>\n",
       "      <td>0.141130</td>\n",
       "      <td>0.099934</td>\n",
       "      <td>0.623148</td>\n",
       "      <td>0.267659</td>\n",
       "      <td>0.174131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290042</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.513339</td>\n",
       "      <td>0.168292</td>\n",
       "      <td>0.031914</td>\n",
       "      <td>0.296281</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.177520</td>\n",
       "      <td>0.057554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>0.064557</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.231149</td>\n",
       "      <td>0.116752</td>\n",
       "      <td>0.913380</td>\n",
       "      <td>0.330586</td>\n",
       "      <td>0.175307</td>\n",
       "      <td>0.937380</td>\n",
       "      <td>0.464801</td>\n",
       "      <td>0.263179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494600</td>\n",
       "      <td>0.119239</td>\n",
       "      <td>0.915678</td>\n",
       "      <td>0.352494</td>\n",
       "      <td>0.097194</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.332203</td>\n",
       "      <td>0.063598</td>\n",
       "      <td>0.818130</td>\n",
       "      <td>0.278857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>0.012224</td>\n",
       "      <td>0.374229</td>\n",
       "      <td>0.052229</td>\n",
       "      <td>0.021358</td>\n",
       "      <td>0.492336</td>\n",
       "      <td>0.076837</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.637155</td>\n",
       "      <td>0.137369</td>\n",
       "      <td>0.080295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324225</td>\n",
       "      <td>0.052534</td>\n",
       "      <td>0.587280</td>\n",
       "      <td>0.170331</td>\n",
       "      <td>0.042367</td>\n",
       "      <td>0.396132</td>\n",
       "      <td>0.169838</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>0.268075</td>\n",
       "      <td>0.093186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      january_avg  january_max  january_average_max  february_avg  \\\n",
       "2607     0.034619     0.726833             0.169660      0.102621   \n",
       "2626     0.025563     0.347593             0.117526      0.063945   \n",
       "2631     0.018289     0.214462             0.072340      0.045558   \n",
       "2657     0.064557     0.814452             0.231149      0.116752   \n",
       "2660     0.012224     0.374229             0.052229      0.021358   \n",
       "\n",
       "      february_max  february_average_max  march_avg  march_max  \\\n",
       "2607      0.919714              0.351934   0.114527   0.978294   \n",
       "2626      0.510123              0.207965   0.137374   0.813030   \n",
       "2631      0.415719              0.141130   0.099934   0.623148   \n",
       "2657      0.913380              0.330586   0.175307   0.937380   \n",
       "2660      0.492336              0.076837   0.042023   0.637155   \n",
       "\n",
       "      march_average_max  april_avg  ...  september_average_max  october_avg  \\\n",
       "2607           0.309300   0.255650  ...               0.510344     0.092981   \n",
       "2626           0.372940   0.238742  ...               0.352374     0.071822   \n",
       "2631           0.267659   0.174131  ...               0.290042     0.056073   \n",
       "2657           0.464801   0.263179  ...               0.494600     0.119239   \n",
       "2660           0.137369   0.080295  ...               0.324225     0.052534   \n",
       "\n",
       "      october_max  october_average_max  november_avg  november_max  \\\n",
       "2607     0.912645             0.290926      0.072014      0.807710   \n",
       "2626     0.683270             0.230175      0.034770      0.498327   \n",
       "2631     0.513339             0.168292      0.031914      0.296281   \n",
       "2657     0.915678             0.352494      0.097194      0.833607   \n",
       "2660     0.587280             0.170331      0.042367      0.396132   \n",
       "\n",
       "      november_average_max  december_avg  december_max  december_average_max  \n",
       "2607              0.344670      0.022011      0.553282              0.143006  \n",
       "2626              0.141312      0.018410      0.219477              0.090823  \n",
       "2631              0.117800      0.013659      0.177520              0.057554  \n",
       "2657              0.332203      0.063598      0.818130              0.278857  \n",
       "2660              0.169838      0.020474      0.268075              0.093186  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_metrics_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313ebd3",
   "metadata": {},
   "source": [
    "### Loading PV Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d9f7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude_rounded</th>\n",
       "      <th>longitude_rounded</th>\n",
       "      <th>orientation</th>\n",
       "      <th>tilt</th>\n",
       "      <th>kwp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ss_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>53.53</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>180.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>54.88</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>315.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>54.88</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>225.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>54.88</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>225.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>54.88</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>225.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude_rounded  longitude_rounded  orientation  tilt   kwp\n",
       "ss_id                                                              \n",
       "2405              53.53              -1.63        180.0  35.0  3.36\n",
       "2406              54.88              -1.38        315.0  30.0  1.89\n",
       "2407              54.88              -1.38        225.0  30.0  1.89\n",
       "2408              54.88              -1.38        225.0  30.0  1.89\n",
       "2409              54.88              -1.38        225.0  30.0  1.89"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(datadir + '/pv/metadata.csv')\n",
    "metadata.index = metadata.ss_id\n",
    "metadata.drop(['llsoacd', 'operational_at', 'ss_id'], axis=1, inplace=True)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa15ad",
   "metadata": {},
   "source": [
    "### Converting the PV Metrics Dataframe to a Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_metric_sites = set(pv_metrics_frame.index)\n",
    "nan_fill = pv_metrics_frame.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c92b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_metrics = {}\n",
    "\n",
    "month_names = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "\n",
    "for site_id, (lat, lon, orient, tilt, kwp) in metadata[[\"latitude_rounded\", \"longitude_rounded\", \"orientation\", \"tilt\", \"kwp\"]].iterrows():\n",
    "    for month_number, month in enumerate(month_names, start=1):\n",
    "        key = (lat, lon, orient, tilt, kwp)\n",
    "        metric_names = [\"_\".join([month, metric]) for metric in [\"avg\", \"max\", \"average_max\"]]\n",
    "        if site_id not in pv_metric_sites:\n",
    "            metrics = nan_fill[metric_names].values\n",
    "        else:\n",
    "            metrics = pv_metrics_frame.loc[site_id, metric_names].values\n",
    "        if np.isnan(metrics).any():\n",
    "            metrics = nan_fill[metric_names].values\n",
    "        pv_metrics.setdefault(month_number, {})[key] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992e1c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(datadir + \"/pv_metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pv_metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ee367",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Now let's run our dataset class to validate that our data is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ca49dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_datasets\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ddde5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml file that is used to configure training runs\n",
    "CONFIG_FILE_NAME = \"train.yaml\"\n",
    "\n",
    "with open(CONFIG_FILE_NAME) as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336c0e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset checking checkpoint\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = get_datasets(\n",
    "    config[\"data_path\"],\n",
    "    (config[\"start_date\"], config[\"end_date\"]),\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    hrv=\"hrv\" in config[\"modalities\"],\n",
    "    weather=\"weather\" in config[\"modalities\"],\n",
    "    metadata=\"metadata\" in config[\"modalities\"],\n",
    "    seed=config[\"seed\"],\n",
    "    pv_features_file=config[\"pv_features_file\"],\n",
    "    test_size=config[\"test_size\"],\n",
    "    hrv_crop=config[\"hrv_crop\"],\n",
    "    weather_crop=config[\"weather_crop\"],\n",
    "    zipped=config[\"zipped\"],\n",
    "    offset_start_time=config[\"offset_start_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3bcb5",
   "metadata": {},
   "source": [
    "# Set up model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670fbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pvlib.solarposition import get_solarposition\n",
    "from datetime import datetime\n",
    "from cartopy import crs\n",
    "from itertools import accumulate\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdac1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29e4ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pvlib/solarposition.py:263: UserWarning: Reloading spa to use numba\n",
      "  warnings.warn('Reloading spa to use numba')\n",
      "/usr/local/lib/python3.10/dist-packages/pvlib/spa.py:940: UserWarning: The number of threads is more than the length of the time array. Only using %s threads.\n",
      "  warnings.warn('The number of threads is more than the length of '\n"
     ]
    }
   ],
   "source": [
    "# Precompile solar position\n",
    "_ = get_solarposition(\n",
    "    time=datetime(2020, 1, 2, 3),\n",
    "    latitude=123.4,\n",
    "    longitude=49.0,\n",
    "    method=\"nrel_numba\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b10828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrv lat lon features\n",
    "delta_geos = 1000.1343488693237\n",
    "ix = np.arange(config[\"hrv_crop\"]) - (config[\"hrv_crop\"] // 2)\n",
    "xx, yy = np.meshgrid(ix, ix)\n",
    "xx_hrv = xx * delta_geos\n",
    "yy_hrv = yy * delta_geos\n",
    "\n",
    "\n",
    "# weather lat lon features\n",
    "delta_nwp = 0.0623\n",
    "ix = np.arange(config[\"weather_crop\"]) - (config[\"weather_crop\"] // 2)\n",
    "xx, yy = np.meshgrid(ix, ix)\n",
    "xx_nwp = xx * delta_nwp\n",
    "yy_nwp = yy * delta_nwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f3b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_coords = crs.Geostationary(central_longitude=9.5, sweep_axis=\"y\")\n",
    "latlon_coords = crs.Geodetic()   \n",
    "def get_hrv_lat_lon_features(lat, lon):\n",
    "    x_geo, y_geo = hrv_coords.transform_point(lon, lat, latlon_coords)\n",
    "\n",
    "    xx_geo = xx_hrv + x_geo\n",
    "    yy_geo = yy_hrv + y_geo\n",
    "\n",
    "    coords = latlon_coords.transform_points(\n",
    "        hrv_coords,\n",
    "        xx_geo, yy_geo\n",
    "    )\n",
    "\n",
    "    xx_lon = coords[..., 0]\n",
    "    yy_lat = coords[..., 1]\n",
    "    features = np.stack((xx_lon, yy_lat), axis=-1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0585bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_solar_incidence(az, el, orient, tilt):\n",
    "    # Assume in degrees\n",
    "    panel_vec = np.array([\n",
    "        np.cos(np.radians(orient)),\n",
    "        np.sin(np.radians(orient)),\n",
    "        np.sin(np.radians(tilt))\n",
    "    ])\n",
    "\n",
    "    solar_vec = np.stack([\n",
    "        np.cos(np.radians(az)),\n",
    "        np.sin(np.radians(az)),\n",
    "        np.sin(np.radians(el))\n",
    "    ], axis=1)\n",
    "\n",
    "    sim = -solar_vec @ panel_vec.T\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a66dbc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(id, split_seed: int):\n",
    "    process_seed = torch.initial_seed()\n",
    "    base_seed = process_seed - id\n",
    "    ss = np.random.SeedSequence(\n",
    "        [id, base_seed, split_seed]\n",
    "    )\n",
    "    np_rng_seed = ss.generate_state(4)\n",
    "    np.random.seed(np_rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44f18e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_collate_fn(batch):\n",
    "    \"\"\"Data is already batched\n",
    "    Weather is already shape (B, C, L, H, W)\n",
    "    \"\"\"\n",
    "    batch = batch[0]\n",
    "    metadata_features = {}\n",
    "    for (lat, lon, orient, tilt, kwp), t0 in zip(batch[\"metadata\"], batch[\"time\"]):\n",
    "        t0 = pd.Timestamp(t0) - pd.Timedelta(hours=1)\n",
    "        # 60 timestamp including first hour and prediction window\n",
    "        ts = list(accumulate([pd.Timedelta(minutes=5)] * 59, initial=t0))\n",
    "        ts = pd.DatetimeIndex(ts)\n",
    "        solar_pos = get_solarposition(\n",
    "            time=ts, \n",
    "            latitude=lat,\n",
    "            longitude=lon,\n",
    "            method=\"nrel_numba\"\n",
    "        )\n",
    "\n",
    "        # Scale to [0, 1] for SSP\n",
    "        doy = ts.day_of_year.values / 365\n",
    "        mod = ((ts.hour.values * 60) + ts.minute.values) / (24 * 60)\n",
    "        \n",
    "        metadata_features.setdefault(\"time\", []).append(np.stack([\n",
    "            mod,\n",
    "            doy\n",
    "        ], axis=1))\n",
    "\n",
    "        # Weather time features on the hour\n",
    "        t0 = t0.floor(\"60min\")  # t0 already 1 hr before\n",
    "        ts = list(accumulate([pd.Timedelta(minutes=60)] * 5, initial=t0))\n",
    "        ts = pd.DatetimeIndex(ts)\n",
    "        doy = ts.day_of_year.values / 365\n",
    "        mod = ((ts.hour.values * 60) + ts.minute.values) / (24 * 60)\n",
    "        metadata_features.setdefault(\"weather_time\", []).append(np.stack([\n",
    "            mod,\n",
    "            doy\n",
    "        ], axis=1))\n",
    "\n",
    "        lon_xx = lon + xx_nwp\n",
    "        lat_yy = lat + yy_nwp\n",
    "        metadata_features.setdefault(\"location\", []).append(np.stack([\n",
    "            lon_xx,\n",
    "            lat_yy\n",
    "        ], axis=-1))\n",
    "\n",
    "        metadata_features.setdefault(\"hrv_location\", []).append(get_hrv_lat_lon_features(lat, lon))\n",
    "\n",
    "        # Scale to [0, 1] for SSP\n",
    "        az = solar_pos[\"azimuth\"].values / 360\n",
    "        el = solar_pos[\"apparent_elevation\"].values / 360\n",
    "        metadata_features.setdefault(\"azel\", []).append(np.stack([\n",
    "            az,\n",
    "            el\n",
    "        ], axis=1))\n",
    "\n",
    "        # Scale to [0, 1] for SSP\n",
    "        orient = orient / 360\n",
    "        tilt = tilt / 360\n",
    "        metadata_features.setdefault(\"static\", []).append(np.array([\n",
    "            [orient,\n",
    "            tilt,\n",
    "            kwp]\n",
    "        ]))\n",
    "        \n",
    "    batch = {k: torch.FloatTensor(v) for k, v in batch.items() if k not in [\"time\", \"metadata\"]}\n",
    "    for k, v in metadata_features.items():\n",
    "        batch[k] = torch.FloatTensor(np.stack(v))\n",
    "    batch[\"pv\"] = batch[\"pv\"].unsqueeze(-1)\n",
    "    batch[\"pv_features\"] = batch[\"pv_features\"].unsqueeze(-2)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "803c2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=metadata_collate_fn,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=partial(worker_init_fn, split_seed=0),\n",
    "    num_workers=config[\"num_workers\"]\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    collate_fn=metadata_collate_fn, \n",
    "    pin_memory=True,\n",
    "    worker_init_fn=partial(worker_init_fn, split_seed=0),\n",
    "    num_workers=config[\"num_workers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2aee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 7
}
